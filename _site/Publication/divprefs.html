

<!doctype html>
<html lang="en" class="no-js">
  <head>
    

<meta charset="utf-8">



<!-- begin SEO -->









<title>Whose Preferences? Differences in Fairness Preferences and Their Impact on the Fairness of AI Utilizing Human Feedback - Florian E. Dorner</title>







<meta property="og:locale" content="en-US">
<meta property="og:site_name" content="Florian E. Dorner">
<meta property="og:title" content="Whose Preferences? Differences in Fairness Preferences and Their Impact on the Fairness of AI Utilizing Human Feedback">


  <link rel="canonical" href="http://localhost:4000/Publication/divprefs">
  <meta property="og:url" content="http://localhost:4000/Publication/divprefs">



  <meta property="og:description" content="Human preferences about judgments in text classification are not invariant accross demographic groups">









  <meta property="og:type" content="article">
  <meta property="article:published_time" content="2024-06-09T00:00:00+02:00">













<!-- end SEO -->


<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="Florian E. Dorner Feed">

<!-- http://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">

<meta http-equiv="cleartype" content="on">
    

<!-- start custom head snippets -->

<meta name="msapplication-TileColor" content="#000000">
<meta name="theme-color" content="#ffffff">
<link rel="stylesheet" href="http://localhost:4000/assets/css/academicons.css" />


<!-- Support for MatJax -->
<script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

<!-- end custom head snippets -->
  </head>

  <body>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->
    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        <button><div class="navicon"></div></button>
        <ul class="visible-links">
          <li class="masthead__menu-item masthead__menu-item--lg"><a href="http://localhost:4000/">Florian E. Dorner</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/Publications/">Publications</a></li>
          
            
            <li class="masthead__menu-item"><a href="http://localhost:4000/Tools/">Tools</a></li>
          
        </ul>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>

    





<div id="main" role="main">
  


  <div class="sidebar sticky">
  



<div itemscope itemtype="http://schema.org/Person">

  <div class="author__avatar">
    
    	<img src="http://localhost:4000/images/2022_04_17_6936_crop.JPG" class="author__avatar" alt="Florian E. Dorner">
    
  </div>

  <div class="author__content">
    <h3 class="author__name">Florian E. Dorner</h3>
    
    <p class="author__bio">PhD student in Machine Learning</p>
  </div>

  <div class="author__urls-wrapper">
    <button class="btn btn--inverse">Follow</button>
    <ul class="author__urls social-icons">
      <!-- Font Awesome icons / Biographic information  -->
      
        <li class="author__desktop"><i class="fa-solid fa-location-dot icon-pad-right" aria-hidden="true"></i>Tübingen / Zürich</li>
      
      
        <li class="author__desktop"><i class="fa fa-solid fa-building-columns icon-pad-right" aria-hidden="true"></i>MPI-IS / ETH Zürich</li>
      
      
      
        <li><a href="mailto:florian.dorner [at] tuebingen.mpg.de"><i class="fas fa-fw fa-envelope icon-pad-right" aria-hidden="true"></i>Email</a></li>
      

      <!-- Font Awesome and Academicons icons / Academic websites -->
            
      
        <li><a href="https://scholar.google.com/citations?user=aYHq31IAAAAJ&hl=en"><i class="ai ai-google-scholar icon-pad-right"></i>Google Scholar</a></li>
      
      
      
                              
      

      <!-- Font Awesome icons / Repositories and software development -->
      
            
            
      
        <li><a href="https://github.com/flodorner"><i class="fab fa-fw fa-github icon-pad-right" aria-hidden="true"></i>Github</a></li>
      
            
            

      <!-- Font Awesome icons / Social media -->
      
      
            
      
                  
                  
      
            
            
      
        <li><a href="https://www.linkedin.com/in/florian-dorner-242b48172"><i class="fab fa-fw fa-linkedin icon-pad-right" aria-hidden="true"></i>LinkedIn</a></li>
            
      
            
                  
            
      
            
            
      
              
      
                      
      
      
            
    </ul>
  </div>
</div>

  
  </div>


  <article class="page" itemscope itemtype="http://schema.org/CreativeWork">
    
    <meta itemprop="headline" content="Whose Preferences? Differences in Fairness Preferences and Their Impact on the Fairness of AI Utilizing Human Feedback">
    
    <meta itemprop="description" content="Human preferences about judgments in text classification are not invariant accross demographic groups">
    
    
    <meta itemprop="datePublished" content=" June 09, 2024">
    

    <div class="page__inner-wrap">
      
      <header>
        <h1 class="page__title" itemprop="headline">Whose Preferences? Differences in Fairness Preferences and Their Impact on the Fairness of AI Utilizing Human Feedback
 <a href=https://arxiv.org/abs/2406.05902> (pdf)</a> </h1>
        
        
        

        
        <!--Published in -->
        <p>Emilia Agis Lerner, <strong>Florian E. Dorner</strong>, Elliott Ash, and Naman Goel </p>
        <p> <strong>Annual Meeting of the Association for Computational Linguistics 2024</strong> </p>
        <!--, 2024 -->
        
      </header>
      

      <section class="page__content" itemprop="text">
        <p>There is a growing body of work on learning from human feedback to align various aspects of machine learning systems with human values and preferences. We consider the setting of fairness in content moderation, in which human feedback is used to determine how two comments – referencing different sensitive attribute groups – should be treated in comparison to one another. With a novel dataset collected from Prolific and MTurk, we find significant gaps in fairness preferences depending on the race, age, political stance, educational level, and LGBTQ+ identity of annotators. We also demonstrate that demographics mentioned in text have a strong influence on how users perceive individual fairness in moderation. Further, we find that differences also exist in downstream classifiers trained to predict human preferences. Finally, we observe that an ensemble, giving equal weight to classifiers trained on annotations from different demographics, performs better for different demographic intersections; compared to a single classifier that gives equal weight to each annotation.</p>



        <!---->

        
      </section>

      <footer class="page__meta">
        
        




      </footer>

      <!--

<section class="page__share">
  

  <a href="https://twitter.com/intent/tweet?text=http://localhost:4000/Publication/divprefs" class="btn btn--twitter" title="Share on Twitter"><i class="fab fa-twitter" aria-hidden="true"></i><span> Twitter</span></a>

  <a href="https://www.facebook.com/sharer/sharer.php?u=http://localhost:4000/Publication/divprefs" class="btn btn--facebook" title="Share on Facebook"><i class="fab fa-facebook" aria-hidden="true"></i><span> Facebook</span></a>

  <a href="https://www.linkedin.com/shareArticle?mini=true&url=http://localhost:4000/Publication/divprefs" class="btn btn--linkedin" title="Share on LinkedIn"><i class="fab fa-linkedin" aria-hidden="true"></i><span> LinkedIn</span></a>
</section>-->

      


  <nav class="pagination">
    
      <a href="http://localhost:4000/Publication/labelnoise" class="pagination--pager" title="Don’t Label Twice: Quantity Beats Quality when Comparing Binary Classifiers on a Budget
">Previous</a>
    
    
      <a href="http://localhost:4000/Publication/TTT" class="pagination--pager" title="Training on the Test Task Confounds Evaluation and Emergence
">Next</a>
    
  </nav>

    </div>

    
  </article>

  
  
</div>

    <div class="page__footer">
      <footer>
        
        


<div class="page__footer-follow">
  <ul class="social-icons">
    
    <!--
    <li><a href="http://github.com/flodorner"><i class="fab fa-github" aria-hidden="true"></i> GitHub</a>
    </li>
    -->
    
    
  </ul>
</div>


<style>
  .container {
    display: flex;
    /* Use flexbox */
    justify-content: space-between;
    /* Add space between the boxes */
    align-items: center;
    /* Center vertically */
  }

  .box {
    width: 50%;
    /* Each div takes 50% width */
    border: 1px solid black;
    padding: 20px;
  }
</style>

<div class="container">
  <div class="page__footer-copyright">&copy; 2025 Florian Dorner. Powered by <a href="http://jekyllrb.com"
      rel="nofollow">Jekyll</a> &amp; <a
      href="https://github.com/academicpages/academicpages.github.io">AcademicPages</a>, a fork of <a
      href="https://mademistakes.com/work/minimal-mistakes-jekyll-theme/" rel="nofollow">Minimal Mistakes</a>.</div>

  <div class="page__footer-copyright">
    Max Planck Institut für Intelligente Systeme <br>
    Max-Planck-Ring 4 <br>
    72076 Tübingen <br>
    Germany <br> </div>
</div>
      </footer>
    </div>

    <script src="http://localhost:4000/assets/js/main.min.js"></script>





  </body>
</html>

